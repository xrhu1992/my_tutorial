# LLM
## 基本概念
* token: 词元，不可再拆分的最小语义单位
* LM (Language Model): 语言模型，预测下一个 token 的概率分布，语言模型的概率预测与<mark>上下文</mark>和<mark>语料库</mark>息息相关

* 条件概率链式法则  
  假设词元序列为 $( w_1, w_2, ..., w_n )$ ，则该序列的联合概率可以表示为：
  ```math 
  P(w_1, w_2, ..., w_n) = P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)...P(w_n|w_1,w_2,...,w_{n-1})
  ```

* n-阶马尔可夫假设  
  为了简化条件概率的计算，假设当前词元只与前面n个词元相关
  ```math
  P(w_n|w_1,w_2,...,w_{n-1}) \approx P(w_n|w_{n-n},w_{n-(n-1)},...,w_{n-1})
  ```

* N-gram 模型
  - 通过假设当前词元只与前面 $N-1$ 个词元相关，简化条件概率的计算
  - 例如，二元模型 (Bigram) 假设 $P(w_n|w_1,w_2,...,w_{n-1}) \approx P(w_n|w_{n-1})$ ，则联合概率可表示为：
```math
P(w_1, w_2, ..., w_n) \approx P(w_1)P(w_2|w_1)P(w_3|w_2)...P(w_n|w_{n-1})
``` 
